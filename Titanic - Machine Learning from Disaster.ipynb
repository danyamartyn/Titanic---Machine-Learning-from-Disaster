{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e0174cb8-2f79-4e18-9acc-d87e62486d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "from scipy.stats import skew, norm, zscore\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn import svm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552642b2-c40d-44d9-ba69-6069dab5222a",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Importing and combining data:\n",
    "You begin by importing your train and test data and combining them into a single dataframe. This allows you to perform data preprocessing on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "09f141b7-07fc-4898-b218-f178ce82cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = r'C:\\Users\\User\\Desktop\\Main Folder\\Job\\Projects\\Titanic - Machine Learning from Disaster\\\\'\n",
    "train = pd.read_csv(path_to_data + str('train.csv'))\n",
    "test = pd.read_csv(path_to_data + str('test.csv'))\n",
    "\n",
    "survived_list = train['Survived']\n",
    "\n",
    "train_index = train.index\n",
    "test_index = test.index\n",
    "\n",
    "train = train.drop(['Survived'], 1)\n",
    "data = pd.concat([train, test]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2a50bdd5-664c-44ea-b383-015449fbde32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b05c9bc-f481-42c7-9a33-d2a00f8bc002",
   "metadata": {},
   "source": [
    "##### Dropping uninformative columns: \n",
    "After combining your data, you identify columns that are not informative for your problem and drop them from the dataframe. This helps to reduce noise and focus on the important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "314353d1-4e00-4513-995f-0337acba4106",
   "metadata": {},
   "outputs": [],
   "source": [
    "unnecessary_columns = ['Name', 'Ticket']\n",
    "\n",
    "def remove_unnecessary_columns(dataframe, unnecessary_columns):\n",
    "    \n",
    "    dataframe = dataframe.drop(unnecessary_columns, 1)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "data = remove_unnecessary_columns(data, unnecessary_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b430b945-bca0-48ce-9710-b637a4f4b30f",
   "metadata": {},
   "source": [
    "##### Checking dataset information: \n",
    "You then display the overall information about your dataset, such as the number of rows, columns, and data types. This helps you to get a better understanding of the data you are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cd537642-90ae-4476-b8b1-a989c0ad1beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  1309 non-null   int64  \n",
      " 1   Pclass       1309 non-null   int64  \n",
      " 2   Sex          1309 non-null   object \n",
      " 3   Age          1046 non-null   float64\n",
      " 4   SibSp        1309 non-null   int64  \n",
      " 5   Parch        1309 non-null   int64  \n",
      " 6   Fare         1308 non-null   float64\n",
      " 7   Cabin        295 non-null    object \n",
      " 8   Embarked     1307 non-null   object \n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 92.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30411d8-0095-47a3-80a4-abf963a40b01",
   "metadata": {},
   "source": [
    "##### Handling missing values: \n",
    "Next, you check the amount of null values in each column of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "24d9d742-3971-4e96-a127-f5d4c24182a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age          263\n",
       "Fare           1\n",
       "Cabin       1014\n",
       "Embarked       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_with_nan = data.isna().sum()[data.isna().sum() != 0]\n",
    "columns_with_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b23bd14-194e-42a0-815b-e4bd287c099f",
   "metadata": {},
   "source": [
    "For columns 'Age' and 'Fare' which contain missing values, you fill them in using mean values based on the similarity of other values in the same columns. Specifically,\n",
    "- Find the most correlated columns to 'Age' (let's say 'Pclass' and 'SibSp');\n",
    "- Find standard deviations for 'Pclass' and 'SibSp';\n",
    "- Use that standard deviations to find similar values in columns 'Pclass' and 'SibSp' to row 'x' values;\n",
    "- Take the mean of 'Age' of those similar rows and set it instead of 'nan' value in row 'x' columns 'Age'\n",
    "\n",
    "This helps to ensure that your dataset is complete and suitable for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eec975f9-2da2-439f-8c13-d3f569ba6c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['Age', 'Fare']:\n",
    "    \n",
    "    values = []\n",
    "    \n",
    "    correlated_columns = abs(data.corr()[column]).sort_values(ascending = False)[1:3].index\n",
    "    indecies = data.loc[data[column].isna(), column].index\n",
    "    \n",
    "    for index in indecies:\n",
    "        \n",
    "        value = data[(data[correlated_columns[0]] == data.iloc[index][correlated_columns[0]]) &\n",
    "                 (data[correlated_columns[1]] == data.iloc[index][correlated_columns[1]])][column].mean(skipna = True)\n",
    "        \n",
    "        values.append(value)\n",
    "        \n",
    "    data.loc[indecies, column] = values        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37282eb-e6d4-457b-b40c-b6d12de365da",
   "metadata": {},
   "source": [
    "##### Data type conversion and feature engineering: \n",
    "You convert the 'Age' column into 'int' datatype and fill missing values in object columns with \"NA\". You also separate the first character of the cabin column and set it as a new value in the 'Cabin' column. Additionally, you create three new columns: \n",
    "- 'are_siblings' to indicate whether a passenger has any siblings;\n",
    "- 'are_parents' to indicate whether a passenger has any parents;\n",
    "- 'family_size' to indicate the size of a family traveling with the passenger.\n",
    "\n",
    "These steps help to further refine your dataset and create more meaningful features for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "67c1bf25-c848-4f54-96a4-e9d59e7d5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'] = data['Age'].astype(int)\n",
    "\n",
    "data[['Cabin', 'Embarked']] = data[['Cabin', 'Embarked']].fillna('NA')\n",
    "data['Cabin'] = data['Cabin'].apply(lambda x: x[0] if isinstance(x, str) and x != 'NA' else x)\n",
    "\n",
    "data['are_siblings'] = data['SibSp'].apply(lambda x: 1 if x != 0 else 0)\n",
    "data['are_parents'] = data['Parch'].apply(lambda x: 1 if x != 0 else 0)\n",
    "data['family_size'] = data['SibSp'] + data['Parch']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482c1e2-a8cf-492f-ab16-1f96d539df59",
   "metadata": {},
   "source": [
    "##### Descriptive statistics: \n",
    "You check the descriptive statistics of the dataset to get an overview of the range, mean, and standard deviation of each variable. This helps to identify any potential outliers or data skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6e2f26b7-1175-4d87-a0f1-a278f59c8a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>1309.0</td>\n",
       "      <td>2.294882</td>\n",
       "      <td>0.837836</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1309.0</td>\n",
       "      <td>29.427044</td>\n",
       "      <td>13.184479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>37.000</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>1309.0</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>1309.0</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>1309.0</td>\n",
       "      <td>33.277580</td>\n",
       "      <td>51.742932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>31.275</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are_siblings</th>\n",
       "      <td>1309.0</td>\n",
       "      <td>0.319328</td>\n",
       "      <td>0.466394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are_parents</th>\n",
       "      <td>1309.0</td>\n",
       "      <td>0.234530</td>\n",
       "      <td>0.423867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family_size</th>\n",
       "      <td>1309.0</td>\n",
       "      <td>0.883881</td>\n",
       "      <td>1.583639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count       mean        std  min      25%      50%     75%  \\\n",
       "Pclass        1309.0   2.294882   0.837836  1.0   2.0000   3.0000   3.000   \n",
       "Age           1309.0  29.427044  13.184479  0.0  22.0000  27.0000  37.000   \n",
       "SibSp         1309.0   0.498854   1.041658  0.0   0.0000   0.0000   1.000   \n",
       "Parch         1309.0   0.385027   0.865560  0.0   0.0000   0.0000   0.000   \n",
       "Fare          1309.0  33.277580  51.742932  0.0   7.8958  14.4542  31.275   \n",
       "are_siblings  1309.0   0.319328   0.466394  0.0   0.0000   0.0000   1.000   \n",
       "are_parents   1309.0   0.234530   0.423867  0.0   0.0000   0.0000   0.000   \n",
       "family_size   1309.0   0.883881   1.583639  0.0   0.0000   0.0000   1.000   \n",
       "\n",
       "                   max  \n",
       "Pclass          3.0000  \n",
       "Age            80.0000  \n",
       "SibSp           8.0000  \n",
       "Parch           9.0000  \n",
       "Fare          512.3292  \n",
       "are_siblings    1.0000  \n",
       "are_parents     1.0000  \n",
       "family_size    10.0000  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('PassengerId', 1).describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16eb5c-584f-47f9-9335-a2c3ca24747d",
   "metadata": {},
   "source": [
    "##### Skewness and outlier detection: \n",
    "You check for data skewness and clean any outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "af857155-1222-4eba-8cf6-ac42b51e086a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fare            4.369316\n",
       "SibSp           3.844220\n",
       "Parch           3.669078\n",
       "family_size     2.853078\n",
       "are_parents     1.254527\n",
       "are_siblings    0.775947\n",
       "Age             0.503033\n",
       "Pclass         -0.598647\n",
       "dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewness = data.drop('PassengerId', 1).skew()\n",
    "skewness.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f4a0f-522b-4e99-8197-4e68d1666685",
   "metadata": {},
   "source": [
    "Specifically, you consider data with a skewness threshold over 1 as skewed and apply different transformations, such as:\n",
    "- square root;\n",
    "- cube root;\n",
    "- logarithm;\n",
    "- BoxCox transformations,\n",
    "\n",
    "to find the best transformation for each skewed column. You then apply these transformations to the skewed columns, resulting in a reduction in the number of outliers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "88d06ef2-e650-424b-920f-8e6da6aa095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_root_transformation(dataframe, columns):\n",
    "    \n",
    "    dataframe[columns] = np.sqrt(dataframe[columns]+0.001)\n",
    "    return dataframe\n",
    "\n",
    "def cube_root_transformation(dataframe, columns):\n",
    "    \n",
    "    dataframe[columns] = (dataframe[columns]+0.001)**(1/3)\n",
    "    return dataframe\n",
    "\n",
    "def logarithm_transformation(dataframe, columns):\n",
    "    \n",
    "    dataframe[columns] = np.log(dataframe[columns]+0.001)\n",
    "    return dataframe\n",
    "\n",
    "def boxcox_transformation(dataframe, column):\n",
    "    dataframe[column], _ = boxcox(dataframe[column] + 0.001)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "05e34ace-3763-49b7-8499-6f7eda90b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(dataframe, threshold=4):\n",
    "    \n",
    "    zscores = pd.DataFrame(np.abs(zscore(dataframe)), columns=dataframe.columns, index=dataframe.index)\n",
    "\n",
    "    outliers = zscores > threshold\n",
    "\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b86ff018-a9b5-4e5b-bd57-f1e5b1e3da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_transformation = pd.DataFrame()\n",
    "\n",
    "variables = []\n",
    "before_transform = []\n",
    "best_transformer = []\n",
    "logs = []\n",
    "squares = []\n",
    "cubes = []\n",
    "boxcox_list = []\n",
    "\n",
    "for variable in skewness.index:\n",
    "    \n",
    "\n",
    "    variables.append(variable)\n",
    "    check_column = data[[variable]]\n",
    "    before_transform.append(np.abs(data[[variable]].skew()[variable]))\n",
    "    square = np.abs(square_root_transformation(check_column, variable).skew()[variable])\n",
    "    cube = np.abs(cube_root_transformation(check_column, variable).skew()[variable])\n",
    "    log = np.abs(logarithm_transformation(check_column, variable).skew()[variable])\n",
    "    from scipy.stats import boxcox\n",
    "    bxcx = np.abs(boxcox_transformation(data.copy(), variable).skew()[variable])\n",
    "\n",
    "    best_dict = {'cube': cube, 'square': square, 'log': log, 'boxcox': bxcx}\n",
    "    min_var = min(best_dict, key=lambda x: best_dict[x])\n",
    "    best_transformer.append(min_var)\n",
    "    logs.append(log)\n",
    "    squares.append(square)\n",
    "    cubes.append(cube)\n",
    "    boxcox_list.append(bxcx)\n",
    "\n",
    "best_transformation['variable'] = variables\n",
    "best_transformation['best_transformer'] = best_transformer\n",
    "best_transformation['square'] = squares\n",
    "best_transformation['cube'] = cubes\n",
    "best_transformation['logs'] = logs\n",
    "best_transformation['boxcox'] = boxcox_list\n",
    "best_transformation['before_transform'] = before_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e552b1da-414b-4cc3-b1b1-a504721065d6",
   "metadata": {},
   "source": [
    "Below you can find a dataframe below that displays all the variables along with the different transformations applied to them. The purpose of this is to identify the most effective transformation for each variable and determine how each transformation affects the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b7656d61-dd04-44bd-98f5-cc6f45493cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>best_transformer</th>\n",
       "      <th>square</th>\n",
       "      <th>cube</th>\n",
       "      <th>logs</th>\n",
       "      <th>boxcox</th>\n",
       "      <th>before_transform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fare</td>\n",
       "      <td>cube</td>\n",
       "      <td>2.090228</td>\n",
       "      <td>0.083792</td>\n",
       "      <td>3.419629</td>\n",
       "      <td>0.322839</td>\n",
       "      <td>4.369316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>boxcox</td>\n",
       "      <td>1.435691</td>\n",
       "      <td>0.872920</td>\n",
       "      <td>0.802988</td>\n",
       "      <td>0.777090</td>\n",
       "      <td>3.844220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parch</td>\n",
       "      <td>boxcox</td>\n",
       "      <td>1.665244</td>\n",
       "      <td>1.320121</td>\n",
       "      <td>1.274214</td>\n",
       "      <td>1.254623</td>\n",
       "      <td>3.669078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>family_size</td>\n",
       "      <td>boxcox</td>\n",
       "      <td>1.106536</td>\n",
       "      <td>0.548681</td>\n",
       "      <td>0.461122</td>\n",
       "      <td>0.431680</td>\n",
       "      <td>2.853078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>are_parents</td>\n",
       "      <td>boxcox</td>\n",
       "      <td>1.254527</td>\n",
       "      <td>1.254527</td>\n",
       "      <td>1.254527</td>\n",
       "      <td>1.254527</td>\n",
       "      <td>1.254527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>are_siblings</td>\n",
       "      <td>square</td>\n",
       "      <td>0.775947</td>\n",
       "      <td>0.775947</td>\n",
       "      <td>0.775947</td>\n",
       "      <td>0.775947</td>\n",
       "      <td>0.775947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>boxcox</td>\n",
       "      <td>0.709361</td>\n",
       "      <td>0.783271</td>\n",
       "      <td>0.819105</td>\n",
       "      <td>0.460233</td>\n",
       "      <td>0.598647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>boxcox</td>\n",
       "      <td>0.837023</td>\n",
       "      <td>3.431680</td>\n",
       "      <td>6.521866</td>\n",
       "      <td>0.091007</td>\n",
       "      <td>0.503033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       variable best_transformer    square      cube      logs    boxcox  \\\n",
       "4          Fare             cube  2.090228  0.083792  3.419629  0.322839   \n",
       "2         SibSp           boxcox  1.435691  0.872920  0.802988  0.777090   \n",
       "3         Parch           boxcox  1.665244  1.320121  1.274214  1.254623   \n",
       "7   family_size           boxcox  1.106536  0.548681  0.461122  0.431680   \n",
       "6   are_parents           boxcox  1.254527  1.254527  1.254527  1.254527   \n",
       "5  are_siblings           square  0.775947  0.775947  0.775947  0.775947   \n",
       "0        Pclass           boxcox  0.709361  0.783271  0.819105  0.460233   \n",
       "1           Age           boxcox  0.837023  3.431680  6.521866  0.091007   \n",
       "\n",
       "   before_transform  \n",
       "4          4.369316  \n",
       "2          3.844220  \n",
       "3          3.669078  \n",
       "7          2.853078  \n",
       "6          1.254527  \n",
       "5          0.775947  \n",
       "0          0.598647  \n",
       "1          0.503033  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_transformation.sort_values(by = 'before_transform', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0ccba40a-ed86-45f6-9c6f-e2e5a5e49c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(dataframe, columns, best_transformation):\n",
    "    \n",
    "    outliers_before_update = find_outliers(dataframe[columns])\n",
    "    outliers_before_update = outliers_before_update[outliers_before_update == True].dropna(how = 'all').shape[0]\n",
    "    print('Amount of outliers begore transformation is: {}'.format(outliers_before_update))\n",
    "    \n",
    "    skewness = dataframe[columns].skew().sort_values(ascending=False)\n",
    "\n",
    "    \n",
    "    for variable in skewness.index:\n",
    "        \n",
    "        if skewness[variable] > 1:\n",
    "            best_transformer = best_transformation[best_transformation['variable'] == variable]['best_transformer'].iloc[-1]\n",
    "\n",
    "            if best_transformer == 'log':\n",
    "                dataframe[variable] = logarithm_transformation(dataframe.copy(), variable)[[variable]]\n",
    "\n",
    "            elif best_transformer == 'square':\n",
    "                dataframe[variable] = square_root_transformation(dataframe.copy(), variable)[[variable]]\n",
    "\n",
    "            elif best_transformer == 'cube':\n",
    "                dataframe[variable] = cube_root_transformation(dataframe.copy(), variable)[[variable]]\n",
    "                \n",
    "            else:\n",
    "                from scipy.stats import boxcox\n",
    "                dataframe[variable] = boxcox_transformation(dataframe.copy(), variable)[[variable]]\n",
    "        \n",
    "    outliers_after_update = find_outliers(dataframe[columns])\n",
    "    outliers_after_update = outliers_after_update[outliers_after_update == True].dropna(how = 'all').shape[0]\n",
    "    print('Amount of outliers after transformation is: {}'.format(outliers_after_update))\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68fc92c-3b8e-4adb-b27b-19982c59a929",
   "metadata": {},
   "source": [
    "Furthermore, it is worth noting that the transformation had a significant positive impact on the amount of outliers in the data. Prior to the transformation, there were 49 outliers present, while after the transformation, the number decreased dramatically to just 4 outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "69379dae-0494-4f5e-8f19-f1a3aff380f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of outliers begore transformation is: 49\n",
      "Amount of outliers after transformation is: 4\n"
     ]
    }
   ],
   "source": [
    "data = feature_engineering(data.copy(), best_transformation.variable, best_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d10f1db9-e116-4920-a785-b6b844461ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total amount of oultiers is 4\n",
      "============================================================\n",
      "The biggest amount of outliers have next variables:\n",
      "Fare      4\n",
      "Pclass    0\n",
      "Age       0\n",
      "SibSp     0\n",
      "Parch     0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outliers = find_outliers(data[best_transformation.variable])\n",
    "print('The total amount of oultiers is {}'.format(outliers[outliers == True].dropna(how = 'all').shape[0]))\n",
    "print('='*60)\n",
    "print(\"The biggest amount of outliers have next variables:\")\n",
    "print(\"{}\\n\".format(outliers.sum().sort_values(ascending=False)[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee5bfe-b9c0-47a5-b47e-9d05f3ad25e4",
   "metadata": {},
   "source": [
    "##### Multicollinearity: \n",
    "You check for multicollinearity among the variables in the dataset by calculating the correlation coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0706a4e1-8302-4178-ada8-8cbe4d928842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(data.drop('PassengerId', 1).corr(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8be42683-7fe6-4d99-a558-3243fa42166d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>are_siblings</th>\n",
       "      <th>are_parents</th>\n",
       "      <th>family_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.038354</td>\n",
       "      <td>0.023957</td>\n",
       "      <td>-0.022418</td>\n",
       "      <td>-0.004362</td>\n",
       "      <td>0.024180</td>\n",
       "      <td>-0.021109</td>\n",
       "      <td>-0.004318</td>\n",
       "      <td>-0.028852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.038354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.436775</td>\n",
       "      <td>-0.094754</td>\n",
       "      <td>-0.035231</td>\n",
       "      <td>-0.676796</td>\n",
       "      <td>-0.098335</td>\n",
       "      <td>-0.035583</td>\n",
       "      <td>-0.136549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.023957</td>\n",
       "      <td>-0.436775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.125293</td>\n",
       "      <td>-0.239869</td>\n",
       "      <td>0.196460</td>\n",
       "      <td>-0.120290</td>\n",
       "      <td>-0.239969</td>\n",
       "      <td>-0.151740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.022418</td>\n",
       "      <td>-0.094754</td>\n",
       "      <td>-0.125293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.421284</td>\n",
       "      <td>0.354764</td>\n",
       "      <td>0.999826</td>\n",
       "      <td>0.421344</td>\n",
       "      <td>0.848476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.004362</td>\n",
       "      <td>-0.035231</td>\n",
       "      <td>-0.239869</td>\n",
       "      <td>0.421284</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333439</td>\n",
       "      <td>0.417468</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.705840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.024180</td>\n",
       "      <td>-0.676796</td>\n",
       "      <td>0.196460</td>\n",
       "      <td>0.354764</td>\n",
       "      <td>0.333439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.354391</td>\n",
       "      <td>0.333062</td>\n",
       "      <td>0.427407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are_siblings</th>\n",
       "      <td>-0.021109</td>\n",
       "      <td>-0.098335</td>\n",
       "      <td>-0.120290</td>\n",
       "      <td>0.999826</td>\n",
       "      <td>0.417468</td>\n",
       "      <td>0.354391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.417540</td>\n",
       "      <td>0.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are_parents</th>\n",
       "      <td>-0.004318</td>\n",
       "      <td>-0.035583</td>\n",
       "      <td>-0.239969</td>\n",
       "      <td>0.421344</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.333062</td>\n",
       "      <td>0.417540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.705736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family_size</th>\n",
       "      <td>-0.028852</td>\n",
       "      <td>-0.136549</td>\n",
       "      <td>-0.151740</td>\n",
       "      <td>0.848476</td>\n",
       "      <td>0.705840</td>\n",
       "      <td>0.427407</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.705736</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PassengerId    Pclass       Age     SibSp     Parch      Fare  \\\n",
       "PassengerId      1.000000 -0.038354  0.023957 -0.022418 -0.004362  0.024180   \n",
       "Pclass          -0.038354  1.000000 -0.436775 -0.094754 -0.035231 -0.676796   \n",
       "Age              0.023957 -0.436775  1.000000 -0.125293 -0.239869  0.196460   \n",
       "SibSp           -0.022418 -0.094754 -0.125293  1.000000  0.421284  0.354764   \n",
       "Parch           -0.004362 -0.035231 -0.239869  0.421284  1.000000  0.333439   \n",
       "Fare             0.024180 -0.676796  0.196460  0.354764  0.333439  1.000000   \n",
       "are_siblings    -0.021109 -0.098335 -0.120290  0.999826  0.417468  0.354391   \n",
       "are_parents     -0.004318 -0.035583 -0.239969  0.421344  0.999986  0.333062   \n",
       "family_size     -0.028852 -0.136549 -0.151740  0.848476  0.705840  0.427407   \n",
       "\n",
       "              are_siblings  are_parents  family_size  \n",
       "PassengerId      -0.021109    -0.004318    -0.028852  \n",
       "Pclass           -0.098335    -0.035583    -0.136549  \n",
       "Age              -0.120290    -0.239969    -0.151740  \n",
       "SibSp             0.999826     0.421344     0.848476  \n",
       "Parch             0.417468     0.999986     0.705840  \n",
       "Fare              0.354391     0.333062     0.427407  \n",
       "are_siblings      1.000000     0.417540     0.848000  \n",
       "are_parents       0.417540     1.000000     0.705736  \n",
       "family_size       0.848000     0.705736     1.000000  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21332060-448d-4091-b949-c85d0865fdbb",
   "metadata": {},
   "source": [
    "Based on the correlation heatmap and the fact that you have only a few variables, you determine that it is better to avoid applying principal component analysis (PCA) in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cf0867-885b-416b-aaaa-076d97e1e021",
   "metadata": {},
   "source": [
    "##### Label encoding: \n",
    "You apply label encoding to object categorical values to convert them into numerical values. This helps to prepare your dataset for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1e17aa18-b542-42c4-af0f-0252d725c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(dataframe):\n",
    "    for col in dataframe.select_dtypes(include='object'):\n",
    "        if len(dataframe[col].unique()) > 2:\n",
    "            le = LabelEncoder()\n",
    "            dataframe[col] = le.fit_transform(dataframe[col])\n",
    "        else:\n",
    "            ohe = OneHotEncoder(drop='if_binary', sparse=False)\n",
    "            dataframe[col] = ohe.fit_transform(dataframe[col].values.reshape(-1, 1))\n",
    "    return dataframe\n",
    "\n",
    "data = label_encode(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badeb3be-186d-4aed-be3d-e0a695465450",
   "metadata": {},
   "source": [
    "##### Train-test split: \n",
    "You divide your dataset back into train and test data and merge the 'Survived' column back into the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6df0eec5-db14-4870-9d4b-7f84397a6272",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.iloc[train_index]\n",
    "train_data['Survived'] = survived_list\n",
    "test_data = data.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5944253c-3c49-44c6-bc6e-186692bb9530",
   "metadata": {},
   "source": [
    "You also check if the 'Survived' column is imbalanced and decide if you need to apply stratification during the train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c77a49b6-3ae0-40c5-af44-6037e492628f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(survived_list, bins=[-0.25, 0.25, 0.75, 1.25], edgecolor='black', color=['green'])\n",
    "plt.xticks([0, 1], ['0', '1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25f160-9aa2-4d56-96f5-1351ec98e889",
   "metadata": {},
   "source": [
    "The column 'Survived' does not appear to be significantly imbalanced, and thus, I will refrain from using stratification during the splitting process. At this point, we will proceed with dividing our training data into separate training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9f9a16ef-5e2a-479a-a41b-27800728b7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = train_data.drop(['PassengerId', 'Survived'], 1)\n",
    "y_train_data = train_data[['Survived']]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_data, y_train_data, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb05548-16c9-4e2e-a160-9d498627d7c3",
   "metadata": {},
   "source": [
    "My decision was to utilize the MinMaxScaler method to standardize both the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5468f19e-730c-43af-a4bb-e6144bc8fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f0614f-38cc-426b-9f21-e86ac0aecd2b",
   "metadata": {},
   "source": [
    "##### Modelling: \n",
    "We will now proceed to experiment with different models and select the one with the highest prediction accuracy on the validation dataset. The models that we will consider are:\n",
    "\n",
    "- Logistic Regression Model\n",
    "- Random Forest Model\n",
    "- SVM Model\n",
    "- Gradient Boosting Model\n",
    "- Neural Network Model\n",
    "\n",
    "\n",
    "To optimize each model's performance, we will apply the grid_search method to find the best combination of hyperparameters for every model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3476e00f-40a9-44ea-b600-d26a55e5ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_model(X_train, X_val, y_train, y_val):\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    param_grid = {'penalty': ['l1', 'l2', None],\n",
    "                  'C': [0.05, 0.1, 0.2, 0.5, 1.0, 2.0, 4.0]}\n",
    "    grid_search = GridSearchCV(estimator = model, param_grid = param_grid, cv = 10)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_penalty = grid_search.best_params_['penalty']\n",
    "    best_C = grid_search.best_params_['C']\n",
    "    \n",
    "    model = LogisticRegression(penalty = best_penalty, C = best_C)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred, pos_label=0)\n",
    "    \n",
    "    return y_pred, accuracy, model, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3821a497-e162-489b-900c-2180f920bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_model(X_train, X_val, y_train, y_val):\n",
    "    \n",
    "    model = RandomForestRegressor()\n",
    "    param_grid = {'n_estimators': [25, 50, 75, 100, 150, 300, 500, 750]}\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=10)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_n_estimators = grid_search.best_params_['n_estimators']\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=best_n_estimators)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred, pos_label=0)\n",
    "    \n",
    "    return y_pred, accuracy, model, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cd111277-8fa5-4de8-a908-079f0872a891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_model(X_train, X_val, y_train, y_val):\n",
    "    \n",
    "    model = svm.SVC()\n",
    "    param_grid = {'C': [0.05, 0.1, 0.3, 0.5, 0.75, 1.0, 2.0, 4.0],\n",
    "                  'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                  'gamma': ['scale', 'auto']}\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=10)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_C = grid_search.best_params_['C']\n",
    "    best_kernel = grid_search.best_params_['kernel']\n",
    "    best_gamma = grid_search.best_params_['gamma']\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    model = svm.SVC(C = best_C, kernel = best_kernel, gamma = best_gamma)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred, pos_label=0)\n",
    "    \n",
    "    return y_pred, accuracy, model, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "285c45df-bf03-4970-9dc9-3a227f16e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting_model(X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    model = model = GradientBoostingRegressor()\n",
    "    param_grid = {'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.5],\n",
    "                  'n_estimators': [25, 50, 75, 100, 150, 300, 500, 750]}\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=10)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_learning_rate = grid_search.best_params_['learning_rate']\n",
    "    best_n_estimators = grid_search.best_params_['n_estimators']\n",
    "    \n",
    "    model = GradientBoostingRegressor(learning_rate = best_learning_rate, n_estimators = best_n_estimators)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred, pos_label=0)\n",
    "    \n",
    "    return y_pred, accuracy, model, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f82efda6-fe7a-4c34-b9a4-c0308ab98af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    def create_model(n_layers, layer_size, regularizer):\n",
    "        model = Sequential()\n",
    "        \n",
    "        div = 1\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            model.add(Dense(int(layer_size/div), input_dim=X_train.shape[1], activation='relu', kernel_regularizer=regularizer))\n",
    "            div = 2\n",
    "        model.add(Dense(1, activation='sigmoid', kernel_regularizer=regularizer))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "    model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_layers': [2, 3, 4],\n",
    "        'layer_size': [32, 64, 128],\n",
    "        'regularizer': [regularizers.l2(0.001), regularizers.l2(0.01),\n",
    "                       regularizers.l1(0.001), regularizers.l1(0.01)],\n",
    "        'batch_size': [8, 16, 32]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    best_layer_size = best_params['layer_size']\n",
    "    best_n_layers = best_params['n_layers']\n",
    "    best_regularizer = best_params['regularizer']\n",
    "    best_batch_size = best_params['batch_size']\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    div = 1\n",
    "    \n",
    "    for i in range(best_n_layers):\n",
    "        model.add(Dense(int(best_layer_size/div), input_dim=X_train.shape[1], activation='relu', kernel_regularizer=best_regularizer))\n",
    "        div = 2\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=best_regularizer))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=best_batch_size, callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the model on the training data\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_train = np.round(y_pred_train).astype(int)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    y_pred_val = np.round(y_pred_val).astype(int)\n",
    "    accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "    \n",
    "    f1 = f1_score(y_val, y_pred_val, pos_label=0)\n",
    "    \n",
    "    print('The accuracy on train data is {}.'.format(accuracy_train))\n",
    "    print('The accuracy on val data is {}.'.format(accuracy_val))\n",
    "    print('='*60)\n",
    "    print('Difference between accuracy of val data and train data is {}%.'.format(((accuracy_val/accuracy_train)-1)*100))\n",
    "    \n",
    "    return y_pred_val, accuracy_val, model, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844242b4-848e-4ab5-8dfa-348bf98b4790",
   "metadata": {},
   "source": [
    "The following function trains each model and consolidates their results into a separate dataframe, making it easier to determine the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1c8e534e-03e4-43f8-8333-f7dfd4d25294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    y_pred_lrm, accuracy_lrm, model_lrm, f1_lrm = logistic_regression_model(X_train.copy(), X_val.copy(), y_train.copy(), y_val.copy())\n",
    "    print('Logistic Regression model was successfuly completed')\n",
    "    y_pred_rfm, accuracy_rfm, model_rfm, f1_rfm = random_forest_model(X_train.copy(), X_val.copy(), y_train.copy(), y_val.copy())\n",
    "    print('Random forest model was successfuly completed')\n",
    "    y_pred_svm, accuracy_svm, model_svm, f1_svm = svm_model(X_train.copy(), X_val.copy(), y_train.copy(), y_val.copy())\n",
    "    print('Support Vecotr model was successfuly completed')\n",
    "    y_pred_gbm, accuracy_gbm, model_gbm, f1_gbm = gradient_boosting_model(X_train.copy(), y_train.copy(), X_val.copy(), y_val.copy())\n",
    "    print('Gradient Boosting model was successfuly completed')\n",
    "    y_pred_nn, accuracy_nn, model_nn, f1_nn = neural_network_model(X_train.copy(), y_train.copy(), X_val.copy(), y_val.copy())\n",
    "    print('Neural Network model was successfuly completed')\n",
    "    \n",
    "    models = [model_lrm, model_rfm, model_svm, model_gbm, model_nn]\n",
    "    \n",
    "    final_results = pd.DataFrame(y_val.copy())\n",
    "    model_names = ['Logistic Regression', 'Random forest', 'Support Vecotr', 'Gradient Boosting', 'Neural Network']\n",
    "\n",
    "    final_results['logistic_regression_pred'] = y_pred_lrm\n",
    "    final_results['random_forest_pred'] = y_pred_rfm\n",
    "    final_results['support_vector_pred'] = y_pred_svm\n",
    "    final_results['gradient_boosting_pred'] = y_pred_gbm\n",
    "    final_results['neural_network_pred'] = y_pred_nn\n",
    "    \n",
    "\n",
    "    accuracy = [accuracy_lrm, accuracy_rfm, accuracy_svm, accuracy_gbm, accuracy_nn]\n",
    "    f_scores = [f1_lrm, f1_rfm, f1_svm, f1_gbm, f1_nn]\n",
    "    all_accuracy = {model_name: score for model_name, score in zip(model_names, accuracy)}\n",
    "    all_f_scores = {model_name: score for model_name, score in zip(model_names, f_scores)}\n",
    "    \n",
    "    metric_dict = {'model_names':model_names,\n",
    "                   'accuracy': accuracy,\n",
    "                   'f1_score': f_scores}\n",
    "        \n",
    "    metric_dict = pd.DataFrame(metric_dict)\n",
    "        \n",
    "    return metric_dict, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6153bde3-547d-4446-991b-dea0b4f520cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model was successfuly completed\n",
      "Random forest model was successfuly completed\n",
      "Support Vecotr model was successfuly completed\n",
      "Gradient Boosting model was successfuly completed\n",
      "Epoch 1/50\n",
      "78/78 [==============================] - 1s 3ms/step - loss: 0.6375 - val_loss: 0.6265\n",
      "Epoch 2/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5451 - val_loss: 0.5606\n",
      "Epoch 3/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 0.5699\n",
      "Epoch 4/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5089 - val_loss: 0.5356\n",
      "Epoch 5/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4949 - val_loss: 0.5391\n",
      "Epoch 6/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4947 - val_loss: 0.5200\n",
      "Epoch 7/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4877 - val_loss: 0.5214\n",
      "Epoch 8/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4824 - val_loss: 0.5156\n",
      "Epoch 9/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4737 - val_loss: 0.5101\n",
      "Epoch 10/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4739 - val_loss: 0.5086\n",
      "Epoch 11/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.4979\n",
      "Epoch 12/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4658 - val_loss: 0.5145\n",
      "Epoch 13/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4665 - val_loss: 0.5194\n",
      "Epoch 14/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4577 - val_loss: 0.5012\n",
      "Epoch 15/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4656 - val_loss: 0.5454\n",
      "Epoch 16/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4603 - val_loss: 0.4957\n",
      "Epoch 17/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.5028\n",
      "Epoch 18/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4513 - val_loss: 0.5105\n",
      "Epoch 19/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4490 - val_loss: 0.4876\n",
      "Epoch 20/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4522 - val_loss: 0.4882\n",
      "Epoch 21/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4464 - val_loss: 0.5031\n",
      "Epoch 22/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.4952\n",
      "Epoch 23/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4479 - val_loss: 0.4913\n",
      "Epoch 24/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4458 - val_loss: 0.4855\n",
      "Epoch 25/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4409 - val_loss: 0.4879\n",
      "Epoch 26/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4433 - val_loss: 0.4935\n",
      "Epoch 27/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4413 - val_loss: 0.5009\n",
      "Epoch 28/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4370 - val_loss: 0.5061\n",
      "Epoch 29/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4384 - val_loss: 0.4919\n",
      "Epoch 30/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4321 - val_loss: 0.5026\n",
      "Epoch 31/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 0.4826\n",
      "Epoch 32/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4400 - val_loss: 0.4975\n",
      "Epoch 33/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4383 - val_loss: 0.4936\n",
      "Epoch 34/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4392 - val_loss: 0.4776\n",
      "Epoch 35/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4346 - val_loss: 0.4895\n",
      "Epoch 36/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4343 - val_loss: 0.4986\n",
      "Epoch 37/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4281 - val_loss: 0.4866\n",
      "Epoch 38/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4352 - val_loss: 0.4977\n",
      "Epoch 39/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4337 - val_loss: 0.5203\n",
      "Epoch 40/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4331 - val_loss: 0.4833\n",
      "Epoch 41/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4309 - val_loss: 0.4852\n",
      "Epoch 42/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4284 - val_loss: 0.4802\n",
      "Epoch 43/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4328 - val_loss: 0.4915\n",
      "Epoch 44/50\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4309 - val_loss: 0.4937\n",
      "20/20 [==============================] - 0s 820us/step\n",
      "9/9 [==============================] - 0s 0s/step\n",
      "The accuracy on train data is 0.8378812199036918.\n",
      "The accuracy on val data is 0.8022388059701493.\n",
      "============================================================\n",
      "Difference between accuracy of val data and train data is -4.25387430662777%.\n",
      "Neural Network model was successfuly completed\n"
     ]
    }
   ],
   "source": [
    "metric_dict, models = find_best_model(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ab0e5-dbb1-4b6c-91be-a46e99e3ee5a",
   "metadata": {},
   "source": [
    "##### Results:\n",
    "Upon evaluating the different models, we can observe that the Gradient Boosting Model exhibited the best performance, achieving an accuracy score of 0.00 and an F1 score of 0.00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f5a94b6d-b612-40ce-88a3-bda9dc2d5755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_names</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.772388</td>\n",
       "      <td>0.812308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.820988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vecotr</td>\n",
       "      <td>0.798507</td>\n",
       "      <td>0.835366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.824627</td>\n",
       "      <td>0.858006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.802239</td>\n",
       "      <td>0.845481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_names  accuracy  f1_score\n",
       "0  Logistic Regression  0.772388  0.812308\n",
       "1        Random forest  0.783582  0.820988\n",
       "2       Support Vecotr  0.798507  0.835366\n",
       "3    Gradient Boosting  0.824627  0.858006\n",
       "4       Neural Network  0.802239  0.845481"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "aac38594-da61-43a3-986c-4295c960c1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=0.05, penalty=None),\n",
       " RandomForestRegressor(n_estimators=300),\n",
       " SVC(C=0.1, kernel='poly'),\n",
       " GradientBoostingRegressor(learning_rate=0.05, n_estimators=75),\n",
       " <keras.engine.sequential.Sequential at 0x22a66300400>]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842cd236-01cc-492d-b003-758a35d7ac33",
   "metadata": {},
   "source": [
    "Therefore, we have assigned our Gradient Boosting model to the variable named 'model'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "052b5ae4-1a97-425c-9c6c-bd8fc1fab637",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf0a295-9349-40ee-9380-5e68d38ae298",
   "metadata": {},
   "source": [
    "Next, we will apply MinMax transformation on the test data and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3c47aaee-f0ea-401f-a5a2-753943fb9fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         1\n",
       "2            894         1\n",
       "3            895         1\n",
       "4            896         0\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         0\n",
       "415         1307         1\n",
       "416         1308         1\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_upd = scaler.transform(test_data.copy().drop('PassengerId', 1))\n",
    "\n",
    "predictions = model.predict(test_data_upd)\n",
    "predictions = np.round(predictions).astype(int)\n",
    "\n",
    "predictions_df = pd.DataFrame([list(test['PassengerId']), predictions]).T\n",
    "predictions_df.columns = ['PassengerId', 'Survived']\n",
    "\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a6cacc-6c5a-46f1-b372-c4218594134c",
   "metadata": {},
   "source": [
    "Let's save the final predictions as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "84feabaa-8129-424b-9cb2-4413eb601493",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv(path_to_data+'predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea8b161-60bb-4e2b-918c-baf7337f2570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
